---
published: true
---

Vanishing gradient is a problem that happens when the training method in Neural networks is based on gradient. In this method, the gradient is used for updating parameters in Neural networks, each parameter is changed for the amount of effect it has on the final result in networks.

Vanishing gradient problem referring that the amount of gradient is gradually reduced when the gradient goes to the beginning of the neural network.

|![_config.yml]({{ site.baseurl }}/images/V-E-Gradient/Vanishing_Gradient.png)|
|:--:| 
| *Figure 1 : Vanishing Gradient |


---
published: true
---

Vanishing gradient is a problem that happens when the training method in Neural networks is based on gradient.In this methods, gradient used for updating parameters in Neural networks, each parameter is changed for the amount of effect it has on the final result in networks.

Vanishing gradient problem referring that the amount of gradient is gradually reduced when the gradient goes to the beginning of the neural network.




